
VARUABLES DE TODOS 

ADRIANO
```{r}
library(rio)
elec="https://github.com/adrianoshimante1998/Trabajo-grupal/raw/master/API_EG.ELC.ACCS.ZS_DS2_en_excel_v2_422316.xls"
electricidad=import(elec)
electricidad[,]=lapply(electricidad[,], trimws,whitespace = "[\\h\\v]") # no blanks
electricidad=na.omit(electricidad)
```


YO

BASE DE DATOS DE DESEMPLEO A NIVEL MUNDIAL 
```{r}
library (rio)
Desempleo="https://github.com/claudia1006/PROYECTO/raw/master/DESEMPLEO.xlsx"
dataexcel1d=import(Desempleo)
```

```{r}
dim(dataexcel1d)#filas #columnas 
```

```{r}
row.names(dataexcel1d)=dataexcel1d$Country
```


```{r}
library(stringr)
library(magrittr)
```

```{r}
names(dataexcel1d)[1]='Country'
```

```{r}
dataexcel1d$'2017'=as.numeric(dataexcel1d$`2017`)
```

```{r}
str(dataexcel1d)
```

```{r}
dataexcel1d=na.omit(dataexcel1d)
```


```{r}
summary(dataexcel1d)
```


BASE DE DATOS DE GDP A NIVEL MUNDIAL 
```{r}
GDP="https://github.com/claudia1006/PROYECTO/raw/master/GDP%20PER%20CAPITA%20CURRENT%20%24.xlsx"
dataexcel2gdp=import(GDP)
```

```{r}
names(dataexcel2gdp)[1]='Country'
```

```{r}
row.names(dataexcel2gdp)=dataexcel2gdp$Country
```

```{r}
dataexcel2gdp$'2017'=as.numeric(dataexcel2gdp$`2017`) # a numerico
```

```{r}
str(dataexcel2gdp)
```

```{r}
dataexcel2gdp=na.omit(dataexcel2gdp)
```

```{r}
summary(dataexcel2gdp)
```

```{r}
names(dataexcel1d)[2]="2017 DESEMPLEO"
names(dataexcel2gdp)[2]="2017 GDP PER CAPITA EN $"
```

```{r}
DesempleoyGDP=merge(dataexcel1d,dataexcel2gdp, by.x="Country", by.y="Country")
```

```{r}
summary(DesempleoyGDP)
```



ALFREDO 

Expectativa de vida al nacer en años. Se usará los datos del 2017

Traemos los datos de Github
```{r}
linkvida="https://github.com/Alfredo-Espinoza/Estadistica-2-Parte-individual-del-trabajo-grupal/raw/master/API_SP.DYN.LE00.IN_DS2_en_excel_v2_199538.xlsx"
#Descargando en carpeta
download.file(linkvida, "vida.xlsx")
```

Unimos todas las hojas:
```{r}
library(rio)
basevida <- import_list('vida.xlsx',rbind = TRUE)
```

Borrando columnas innecesarias
```{r}
basevida[2:50]=NULL
```

```{r}
basevida[2:12]=NULL
```

```{r}
basevida[3:13]=NULL
```
Revisamos la base de datos
```{r}
str(basevida)
```
Borramos los NAs
```{r}
basevida=basevida[complete.cases(basevida),]
```

Cambiando nombres de variable
```{r}
names(basevida)[1]="Pais"
names(basevida)[2]="Expectativa de vida en años al nacer (2017)"
```
Eliminamos la primera fila, porque es producto de la suciedad de losd atos.
```{r}
basevida=basevida[-c(1),]
```
Eliminando posibles espacios vacios
```{r}
basevida$Pais=trimws(basevida$Pais,whitespace = "[\\h\\v]")
basevida$`Expectativa de vida en años al nacer (2017)`=trimws(basevida$`Expectativa de vida en años al nacer (2017)`,whitespace = "[\\h\\v]")
```
Revisamos la base de datos
```{r}
str(basevida)
```

Pasando a numérico la variable a estudiar
```{r}
basevida$"Expectativa de vida en años al nacer (2017)"=as.numeric(basevida$"Expectativa de vida en años al nacer (2017)")
```

```{r}
str(basevida)
```


Porcentaje de uso de internet por país. Se usarán los datos del 2017

Trayendo desde Github
```{r}
linkinter="https://github.com/Alfredo-Espinoza/Estadistica-2-Parte-individual-del-trabajo-grupal/raw/master/API_IT.NET.USER.ZS_DS2_en_excel_v2_199844.xlsx"
#Descargando en carpeta
download.file(linkinter, "intercel.xlsx")
```
Unimos todas las hojas:

```{r}
library(rio)
internet <- import_list('intercel.xlsx',rbind = TRUE)
```
Revisamos la base
```{r}
#str(internet)
```

```{r}
internet[2:50]=NULL
```

```{r}
internet[2:12]=NULL
```

```{r}
internet[3:13]=NULL
```
Eliminando los NA
```{r}
internet=internet[complete.cases(internet),]
```
Cambiando nombres de variables.
```{r}
names(internet)[1]="Pais"
```

```{r}
names(internet)[2]="Porcentaje de la población que usa internet (2017)"
```

```{r}
internet$Pais=trimws(internet$Pais,whitespace = "[\\h\\v]")
internet$`Porcentaje de la población que usa internet (2017)`=trimws(internet$`Porcentaje de la población que usa internet (2017)`,whitespace = "[\\h\\v]")
```

```{r}
internet=internet[-1,]
```

```{r}
internet$`Porcentaje de la población que usa internet (2017)`=as.numeric(internet$`Porcentaje de la población que usa internet (2017)`)
```

Revisando
```{r}
str(internet)
```


GEAN PIERRE 


Primero limpiaré la información de la tasa de alfabetización otorgado por la CIA

```{r}
library(htmltab)
literacy=htmltab(doc="https://www.cia.gov/library/publications/resources/the-world-factbook/fields/370.html", which='//*[@id="fieldListing"]')
```

```{r}
str(literacy)
```

```{r, echo=FALSE}
#NO PONER STR
library(stringr)
str_extract_all(literacy$Literacy,pattern="(\\-*\\d+\\.*\\d*)(?=\\%)",simplify = T)
PATRON="(\\-*\\d+\\.*\\d*)(?=\\%)"
COLSUCIA=literacy$Literacy
# UNA COLUMNA
literacy$pop_lit=str_extract_all(string = COLSUCIA,pattern=PATRON,simplify = T)[,1]
# OTRA COLUMNA
literacy$male_lit=str_extract_all(string = COLSUCIA,pattern=PATRON,simplify = T)[,2]
literacy$female_lit=str_extract_all(string = COLSUCIA,pattern=PATRON,simplify = T)[,3]
```

```{r}
head(literacy)
```

```{r}
literacy$Literacy=NULL
```
```{r}
literacy[,-1]=lapply(literacy[,-1], as.numeric)
```

```{r}
str(literacy)
```


```{r}
literacy[!complete.cases(literacy),]
```

```{r}
literacy$Country=trimws(literacy$Country,whitespace = "[\\h\\v]")
```

```{r}
names(literacy)=c("Country", "Literacy Rate", "Male Literacy Rate", "Female Literacy Rate")
```


```{r}
head(literacy)
```

Como extra, importaré y limpiaré otra tabla de alfabetización del worldatlas ya que esta posee más paises en su muestra

```{r}
library(htmltab)
literacy2=htmltab(doc="https://www.worldatlas.com/articles/the-highest-literacy-rates-in-the-world.html", which='//*[@id="artReg-table"]/table')
```

```{r}
literacy2$Rank=NULL
```
```{r}
names(literacy2)=c("Country", "Literacy Rate")
```

```{r}
literacy2=literacy2[-c(196),]
literacy2=literacy2[-c(195),]
#Saldrá NIGER como NA asi que pulsen control+entre solo en literacy2[-c(195),]
```

```{r}
library(stringr)
literacy2$`Literacy Rate`=gsub('%',"",literacy2$`Literacy Rate`)
```


```{r}
literacy2=na.omit(literacy2)
```



Las siguientes variables son las usaré para la calidad de la educación. La primera sería la prueba PISA

```{r}
lkCSV="https://github.com/Geanze/TRABAJO-GRUPAL-ESTAD2/raw/master/Pisa%20rank.csv"
PISA=import(lkCSV)
```
```{r}
dim(PISA)
```

```{r}
PISA$cca2=NULL
PISA$pop2019=NULL
PISA$mathScore=NULL
PISA$readingScore=NULL
PISA$scienceScore=NULL
```
```{r}
names(PISA)=c("Country", "PISA SCORE")
```

```{r}
str(PISA)
```

La segunda variable que tiene relación con la calidad de educación es la Tasa de Escolaridad.

```{r}
lkXLSX="https://github.com/Geanze/TRABAJO-GRUPAL-ESTAD2/raw/master/education-index.xlsx"
Schooling=import(lkXLSX)
```
```{r}
str(Schooling)
```

```{r}
Schooling$`HDI Rank`=NULL
Schooling$`1980`=NULL
Schooling$`1985`=NULL
Schooling$`1990`=NULL
Schooling$`1995`=NULL
Schooling$`2000`=NULL
Schooling$`2005`=NULL
Schooling$`2006`=NULL
Schooling$`2007`=NULL
Schooling$`2008`=NULL
Schooling$`2009`=NULL
Schooling$`2010`=NULL
Schooling$`2011`=NULL
Schooling$`2012`=NULL
```

```{r}
names(Schooling)=c("Country", "Schooling Rate")
```

```{r}
Schooling[c(2)]= lapply(Schooling[c(2)], as.numeric)
```

```{r}
Schooling[complete.cases(Schooling),]
Schooling=na.omit(Schooling)
```

La última variable es la Tasa de Urbanización.

```{r}
lkXLS="https://github.com/Geanze/TRABAJO-GRUPAL-ESTAD2/raw/master/WUP2018-F01-Total_Urban_Rural.xls"
urban=import(lkXLS)
```

```{r}
str(urban)
```

```{r}
urban$Urban=NULL
urban$Rural=NULL
urban$Total=NULL
```
```{r}
names(urban)=c("Country", "Urban Rate")
```

```{r}
urban[complete.cases(urban),]
urban[c(1)]=lapply(urban[c(1)], trimws,whitespace = "[\\h\\v]")
```


```{r}
litur=merge(literacy2,urban,by.x='Country', by.y='Country') 
liturscho=merge(litur,Schooling)
```


```{r}
viint=merge(basevida,internet, by.x='Pais', by.y='Pais')
```

```{r}
names(viint)[1]="Country"

```

UNIENDO TODAS 
```{r}
DesempleoyGDPviint=merge(DesempleoyGDP, viint, by.x = "Country", by.y="Country")
```

```{r}
DeGDPviintliturscho=merge(DesempleoyGDPviint, liturscho, by.x="Country", by.y = "Country")
```

```{r}
names(electricidad)[1]="Country"
```

```{r}
DeGDPviintliturschoelec=merge(DeGDPviintliturscho,electricidad, by.x="Country", by.y="Country")
```

```{r}
str(DeGDPviintliturschoelec)
```
```{r}
DeGDPviintliturschoelec$`Literacy Rate`=as.numeric(DeGDPviintliturschoelec$`Literacy Rate`)
DeGDPviintliturschoelec$Electricity2017=as.numeric(DeGDPviintliturschoelec$Electricity2017)


```

```{r}
str(DeGDPviintliturschoelec)
```
```{r}
FINAL=DeGDPviintliturschoelec
```

```{r}
row.names(FINAL)=FINAL$Country

```

FACTORIAL

Calculando la matriz de correlación 
```{r}
theData=FINAL[,-1] 
```

```{r}
set.seed(2019)
library(polycor)
corMatrix=polycor::hetcor(theData)$correlations #matriz de correlación 
#la matriz de correlación es el símil de daisy en el cluster 

```

```{r}
library(ggcorrplot)

ggcorrplot(corMatrix) #matriz de correlaciones graficada, mientras más rojo más correlacionado positivo , donde hay harta correlacion entre variables algo quieren decir juntas. Cuando hay correlacioón entre algo algo significan juntas 
```

```{r}
ggcorrplot(corMatrix,
          p.mat = cor_pmat(corMatrix), #este es un cuadro que tiene en cuenta la cantidad de filas menor cantidad de datos hace la probabilidad que la correlación sea cero aumente 
          insig = "blank")
```

```{r}
library(psych)
psych::KMO(corMatrix) #prueba si esta matriz de correlación podría ser factorizable, osea si podría tener latente que es la prueba KMO (me dice cuando el overall MSA es mayor que 0,6 quiere decir que tu trabajo tiene esperanzas que algo se pueda  lograr) 
#ACA sale el KMO de cada uno 
```
4. VERIFICANDO LA MATRIZ DE CORRELACIÓN, acá hay 2 hipótesis tienen que salir falso, si en el examen saliera verdadero se tiene que marcar la opción no se puede proceder porque ya la matriz de correlación ha fallado 
```{r}
cortest.bartlett(corMatrix,n=nrow(theData))$p.value>0.05

```

```{r}
library(matrixcalc)

is.singular.matrix(corMatrix)
```
5. DETERMINAR EN CUANTOS FACTORES O VARIABLES LATENTES PODRÍAMOS REDIMENSIONAR LA DATA 

ACA SE TIENE LA PRUEBA DE CUÁNTOS LATENTES PODRÍA HABER COMO LA PRUEBA DE CUÁNTOS CLUSTERS SON ÓPTIMOS
```{r}
fa.parallel(theData,fm = 'ML', fa = 'fa') 

```
Sugiere 1 
REDIMENSIONAR A NUMERO MENOR DE FACTORES 

```{r}
library(GPArotation)
resfa <- fa(theData,nfactors = 2,cor = 'mixed',rotate = "varimax",fm="minres") #SOLO SE CAMBIA EL NFACTORS

```

```{r}
print(resfa$loadings) #SE PIDEN LAS CARGAS QUE SON LOS FACTORES QUE ME DIGA QUÉ VARIABLE PERTENECE A CADA LATENTE QUIEN PESA MAÁS EL QUE TIENE MAYOR NUMERO 
#LOS LOADINGS SON LAS LATENTES 
#SE LLAMAN LATENTES PORQUE AUN NO SE HAN CONSTITUIDO 
```

```{r}
#Resultado mejorado:
print(resfa$loadings,cutoff = 0.51) #ESTO ES PARA VERLO MEJOR, SE UTILIZA EL CUTOFF DONDE SE LE ESTÁ DICIENDO QUE BORRE TODO LO QUE SEA MENOR A 0.51 
```

```{r}
fa.diagram(resfa) #RESULTADO VISUAL 
```

Evaluando el resultado obtenido: 
La Raíz del error cuadrático medio corregida está cerca a cero?
```{r}
resfa$crms #parece que sí, si baja de 0.1 está cerca a cero 
```
La Raíz del error cuadrático medio de aproximación es menor a 0,05? 
```{r}
resfa$RMSEA #VER EL RMSEA, SE MUESTRAN EL INTERVALO DE CONFIANZA 
```
El ÍNDICE DE TUCKER-LEWIS ES MAYOR A 0.9: 
```{r}
resfa$TLI
#si el índice de TUCKER LEWIS 
```
QUÉ VARIABLES APORTARON MÁS A LOS FACTORES? 
```{r}
sort(resfa$communality) #CUALES SEAN UTILIZADO BIEN, ESTO SE PODÍA VER EN EL KMO 
```
QUÉ VARIABLES CONTRIBUYEN A MÁS DE UN FACTOR? 
```{r}
sort(resfa$complexity) #MENCIONA A CUÁNTOS FACTORES APORTAN, EL NÚMERO EN SÍ 
#sale a cuántos, por ejemplo cada variable aportaa 1 factor 
```
POSIBLES VALORES PROYECTADOS 
```{r}
as.data.frame(resfa$scores) #ESTOS SON LOS SCORES DE FACTORIAL 
```

Calculando la matriz de correlación 
```{r}
theData1=FINAL[,-c(1,6,9)] 
```

```{r}
set.seed(2019)
library(polycor)
corMatrix=polycor::hetcor(theData1)$correlations #matriz de correlación 
#la matriz de correlación es el símil de daisy en el cluster 

```

```{r}
library(ggcorrplot)

ggcorrplot(corMatrix) #matriz de correlaciones graficada, mientras más rojo más correlacionado positivo , donde hay harta correlacion entre variables algo quieren decir juntas. Cuando hay correlacioón entre algo algo significan juntas 
```

```{r}
ggcorrplot(corMatrix,
          p.mat = cor_pmat(corMatrix), #este es un cuadro que tiene en cuenta la cantidad de filas menor cantidad de datos hace la probabilidad que la correlación sea cero aumente 
          insig = "blank")
```

```{r}
library(psych)
psych::KMO(corMatrix) #prueba si esta matriz de correlación podría ser factorizable, osea si podría tener latente que es la prueba KMO (me dice cuando el overall MSA es mayor que 0,6 quiere decir que tu trabajo tiene esperanzas que algo se pueda  lograr) 
#ACA sale el KMO de cada uno 
```
4. VERIFICANDO LA MATRIZ DE CORRELACIÓN, acá hay 2 hipótesis tienen que salir falso, si en el examen saliera verdadero se tiene que marcar la opción no se puede proceder porque ya la matriz de correlación ha fallado 
```{r}
cortest.bartlett(corMatrix,n=nrow(theData))$p.value>0.05

```

```{r}
library(matrixcalc)

is.singular.matrix(corMatrix)
```
5. DETERMINAR EN CUANTOS FACTORES O VARIABLES LATENTES PODRÍAMOS REDIMENSIONAR LA DATA 

ACA SE TIENE LA PRUEBA DE CUÁNTOS LATENTES PODRÍA HABER COMO LA PRUEBA DE CUÁNTOS CLUSTERS SON ÓPTIMOS
```{r}
fa.parallel(theData1,fm = 'ML', fa = 'fa') 

```
Sugiere 1 
REDIMENSIONAR A NUMERO MENOR DE FACTORES 

```{r}
library(GPArotation)
resfa <- fa(theData1,nfactors = 1,cor = 'mixed',rotate = "varimax",fm="minres") #SOLO SE CAMBIA EL NFACTORS

```

```{r}
print(resfa$loadings) #SE PIDEN LAS CARGAS QUE SON LOS FACTORES QUE ME DIGA QUÉ VARIABLE PERTENECE A CADA LATENTE QUIEN PESA MAÁS EL QUE TIENE MAYOR NUMERO 
#LOS LOADINGS SON LAS LATENTES 
#SE LLAMAN LATENTES PORQUE AUN NO SE HAN CONSTITUIDO 
```

```{r}
#Resultado mejorado:
print(resfa$loadings,cutoff = 0.51) #ESTO ES PARA VERLO MEJOR, SE UTILIZA EL CUTOFF DONDE SE LE ESTÁ DICIENDO QUE BORRE TODO LO QUE SEA MENOR A 0.51 
```

```{r}
fa.diagram(resfa) #RESULTADO VISUAL 
```

Evaluando el resultado obtenido: 
La Raíz del error cuadrático medio corregida está cerca a cero?
```{r}
resfa$crms #parece que sí, si baja de 0.1 está cerca a cero 
```
La Raíz del error cuadrático medio de aproximación es menor a 0,05? 
```{r}
resfa$RMSEA #VER EL RMSEA, SE MUESTRAN EL INTERVALO DE CONFIANZA 
```
El ÍNDICE DE TUCKER-LEWIS ES MAYOR A 0.9: 
```{r}
resfa$TLI
#si el índice de TUCKER LEWIS 
```
QUÉ VARIABLES APORTARON MÁS A LOS FACTORES? 
```{r}
sort(resfa$communality) #CUALES SEAN UTILIZADO BIEN, ESTO SE PODÍA VER EN EL KMO 
```
QUÉ VARIABLES CONTRIBUYEN A MÁS DE UN FACTOR? 
```{r}
sort(resfa$complexity) #MENCIONA A CUÁNTOS FACTORES APORTAN, EL NÚMERO EN SÍ 
#sale a cuántos, por ejemplo cada variable aportaa 1 factor 
```
POSIBLES VALORES PROYECTADOS 
```{r}
as.data.frame(resfa$scores) #ESTOS SON LOS SCORES DE FACTORIAL 
```



